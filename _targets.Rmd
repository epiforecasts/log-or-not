---
title: "Supplementary information"
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```


# Setup

Set up the workflow pipeline and options. We first load the `targets` package and remove the potentially outdated workflow.

```{r}
library(targets)
library(tarchetypes)
library(tibble)
library(tidyr)
library(dplyr)
library(scoringutils)
library(ggplot2)
library(purrr)
library(here)
tar_unscript()
```

We now define shared global options across our workflow and load R functions from the `R` folder.


```{targets globals, tar_globals = TRUE}
options(tidyverse.quiet = TRUE)
library(purrr)
library(here)
library(tibble)
library(tarchetypes)
functions <- list.files(here("R"), full.names = TRUE)
walk(functions, source)
tar_option_set(
  packages = c("tibble", "tidyr", "dplyr", "scoringutils", "ggplot2", "purrr",
               "readr"),
  error = "continue"
)
```

# Toy example

As a toy example we simulate a grid of data with varying exponential growth rates and a Poisson observation model. As example forecasts we use the same simulation model but add error to either the growth rate or the mean of observations. We do this using the following steps,

- Define a set of growth rates to explore.

```{targets toy_globals, tar_globals = TRUE}
toy_growth_rates <- tibble(r = c(0, 0.1, 0.25, -0.1, -0.25))
```

- Define a grid of scenarios including the true values (zero growth rate and cumulative linear error) for this set of growth rates.

```{targets toy_scenarios, tar_simple = TRUE}
expand_grid(
  init = c(100),
  r = toy_growth_rates$r,
  r_error = c(0, 0.01, 0.05, 0.1, 0.25, -0.01, -0.05, -0.1, -0.25),
  additive_error = c(0, 5, 10, -5, -10)
) |> 
  mutate(id = 1:n())
```

- Simulate each scenario a 1000 times.

```{targets toy_simulations, tar_simple = TRUE}
toy_scenarios |>
  rowwise() |>
  mutate(y = list(
    simulate_exp_poisson(init = init, time = 4, growth = r + r_error,
                         additive_error = additive_error, sims = 1000)
    )
  ) |>
  unnest(cols = c(y))
```

- Filter for the "truth" scenario and keep only the first simulation.

```{targets toy_truth, tar_simple = TRUE}
toy_simulations |>
  filter(r_error == 0, additive_error == 0, sim == 1) |>
  select(init, r, time, true_value = obs)
```

- Filter for all other scenarios.

```{targets toy_forecasts, tar_simple = TRUE}
toy_simulations |>
  select(init, r, r_error, additive_error, time, sample = sim,
         prediction = obs) |>
  left_join(toy_truth, by = c("init", "r", "time"))
```

- Plot simulated observations and forecasts for each growth rate stratified by assumed growth rate and additive error.

```{targets plot_toy_forecasts, tar_interactive = FALSE}
tar_map(
  toy_growth_rates,
  tar_target(
    toy_forecasts_plot,
    plot_toy_forecasts(toy_forecasts, growth = r[[1]],
                       alpha = 0.2, samples = 10)
  ),
  tar_target(
    plot_toy_forecasts_file,
    save_plot(
      toy_forecasts_plot, 
      here("output", "figures", 
           paste0("plot_toy_forecasts_", r[[1]], ".png"))
    ),
    format = "file")
)
```

- Score example forecasts and summarise by growth rate, growth rate error, additive error, and forecast horizon.

```{targets, toy_scores, tar_simple = TRUE}
toy_forecasts |>
  eval_forecasts(
    summarise_by = c("init", "r", "r_error", "additive_error", "time"),
    metrics = c("crps")
  )
```

- Repeat the scoring process but on the log scale. Here we have to pad by a small number as cannot take the log of zero.

```{targets, toy_log_scores, tar_simple = TRUE}
toy_forecasts |>
  mutate(across(.cols = c("true_value", "prediction"), ~ log(.x + 0.001))) |>
  eval_forecasts(
    summarise_by = c("init", "r", "r_error", "additive_error", "time"),
    metrics = c("crps")
  )
```

- Join log and natural scale scores.

```{targets, toy_all_scores, tar_simple = TRUE}
toy_log_scores |>
  mutate(scale = "log") |>
  bind_rows(
    toy_scores |>
      mutate(scale = "natural")
  )
```

- Plot natural scale scores by horizon.

```{targets toy_scores_by_horizon_plot, tar_simple = TRUE}
toy_scores |>
  filter(time <= 4) |>
  plot_toy_scores_by_horizon()
```

- Plot log scale scores by horizon.

```{targets toy_log_scores_by_horizon_plot, tar_simple = TRUE}
toy_log_scores |>
  filter(time <= 4) |>
  plot_toy_scores_by_horizon()
```

- Plot log and natural scale scores for the 4 week horizon.

```{targets toy_scores_by_scale_plot, tar_simple = TRUE}
toy_all_scores |>
  filter(time == 4) |>
  plot_toy_scores_by_scale()
```

- Save output for external use.

```{targets save_toy_output}
list(
  tar_target(
    toy_scores_csv, 
    save_csv(toy_all_scores, here("output/data/toy_all_scores.csv")),
    format = "file"
  ),
  tar_target(
    toy_scores_by_scale_file, 
    save_plot(toy_scores_by_scale_plot, 
              here("output", "figures", "toy_scores_by_scale.png"),
    format = "file")
            ),
  tar_target(
    toy_scores_by_horizon_file, 
    save_plot(toy_scores_by_horizon_plot, 
              here("output", "figures", "toy_scores_by_horizon.png"),
    format = "file")
            ),
  tar_target(
    toy_log_scores_by_horizon_file, 
    save_plot(toy_log_scores_by_horizon_plot, 
              here("output", "figures", "toy_log_scores_by_horizon.png"),
    format = "file")
            )
)
```

# Pipeline

The pipeline can be regenerated by rendering this file,

```{r, eval = FALSE}
rmarkdown::render("_targets.Rmd")
```

The pipeline can then be run using,

```{r, eval = FALSE}
tar_make()
```

The complete pipeline can be visualised using,

```{r, eval = FALSE}
tar_visnetwork()
```

The pipeline can be regenerated and run using the following single step

```{bash, eval = FALSE}
. _targets.sh
```

Alternatively the pipeline can be explored interactively using this notebook.