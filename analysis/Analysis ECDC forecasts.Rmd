---
title: "Log or not - Analysis of ECDC forecasts"
output: html_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE, 
                      warning = FALSE)

library(scoringutils)
library(purrr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)
library(stringr)
library(here)
library(data.table)
library(kableExtra)
library(performance)

recompute_scores <- FALSE
```

```{r}
# helper functions
# ------------------------------------------------------------------------------

make_table <- function(x, caption = "") {
  x %>%
    rename_all(gsub, pattern = "_", replacement = " ") %>%
    rename_all(str_to_sentence) %>%
    mutate_if(is.numeric, round, 2) %>%
    kable(caption = caption) %>%
    kable_styling()
}

# format plot scales
scale_fn <- function(x) {
  ifelse(x >= 1000000, 
         paste0(x / 1000000, "m"), 
         ifelse(x >= 5000,
                paste0(x / 1000, "k"),
                x))
}

```


```{r}
# load data 
# ------------------------------------------------------------------------------

hub_data <- rbindlist(list(
  fread(here("data", "full-data-european-forecast-hub-1.csv")), 
  fread(here("data", "full-data-european-forecast-hub-2.csv"))
)) |>
  unique()

```


```{r eval = recompute_scores}
# score forecasts
# ------------------------------------------------------------------------------

# helper function
score_forecasts <- function(data,
                            summarise_by = c("model", "location", 
                                             "target_end_date", "forecast_date",
                                             "horizon", "target_type"), 
                            scale = c("natural", "log")) {
  if (scale[1] == "log") {
    data <- data |>
      mutate(prediction = log(pmax(prediction, 0) + 1), 
             true_value = log(pmax(true_value, 0) + 1))
  }
  
  data |>
    eval_forecasts(summarise_by = summarise_by) |>
    mutate(scale = scale[1])
}

scores_natural <- score_forecasts(hub_data)
scores_log <- score_forecasts(hub_data, scale = "log")

scores <- bind_rows(scores_natural, scores_log)
fwrite(scores, here("output", "data", "all-scores-european-hub.csv"))
```

```{r}
scores <- fread(here("output", "data", "all-scores-european-hub.csv"))
```

General thoughts?

- Focus on Hub-ensemble or average across all models? 
- Focus on two weeks ahead? 

## Scores across forecast targets

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  ggplot(aes(y = interval_score, x = target_type)) + 
  geom_violin(aes(fill = target_type), alpha = 0.2, color = NA) + 
  geom_boxplot(alpha = 0.5) + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(~ scale, scale = "free") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn, trans = "log10") + 
  labs(y = "Interval score", x = "Target type")
```

*Scores are more comparable across targets*

Mean scores: 
```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(scale, target_type) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  make_table()
```


## Scores across locations

--> could also do this plot with multiplicative scores, i.e. how much higher is a score than the lowest score observed

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble", 
         horizon == 2) |>
  group_by(target_type, location, scale) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  ggplot(aes(y = interval_score, x = reorder(location, -interval_score))) + 
  geom_bar(stat = "identity") + 
  scale_fill_brewer(palette = "Set1", name = "Forecast target") + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  theme_minimal() + 
  theme(legend.position = "none") + 
  scale_y_continuous(labels = scale_fn) + 
  labs(y = "Interval score", x = "Target type")
```

*We see that the scores are much more evenly distributed across locations if we log the data* 


## Scores over time

restrict to a few locations, e.g. GB, FR, ES (highest average scores there)

UK: 

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "GB",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_minimal() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

France: Looks like a data revision

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "FR",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_minimal() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

Spain: 

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble",
         location == "ES",
         horizon == 2) |>
  group_by(target_type, scale) |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = forecast_date)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale, scale = "free_y") + 
  theme_minimal() + 
  labs(x = "Forecast date", y = "WIS relative to smallest observed value")
```

*Overall it looks like there can still be substantial fluctuation in log scores, but maybe slightly less than when scored on an absolute scale. Interestingly, it seems like the smoothing effect is stronger for deaths than for cases.*

## Change of average scores for increasing forecast horizons

```{r}
scores |> 
  filter(model == "EuroCOVIDhub-ensemble") |>
  group_by(scale, target_type, horizon) |>
  summarise(interval_score = mean(interval_score), 
            .groups = "drop_last") |>
  mutate(multiplicative_score = interval_score / min(interval_score)) |>
  ggplot(aes(y = multiplicative_score, x = horizon)) + 
  geom_line() + 
  geom_point() + 
  facet_grid(target_type ~ scale) + 
  theme_minimal() + 
  labs(x = "Forecast horizon in weeks", y = "Multplicative change in interval score")
```

*Slightly less increase on the log scale, but overall not a lot of difference*

## Distribution of scores

--> not sure that is useful

```{r}
scores |>
  ggplot(aes(x = interval_score)) + 
  geom_density() + 
  facet_wrap(~ target_type + scale, scale = "free") + 
  scale_x_continuous(labels = scale_fn)
```


## Fit a model to data

Check fit of the log scale model

```{r echo=TRUE}
reg_log <- scores |>
  filter(scale == "log") |>
  glm(formula = interval_score ~ 1 + model + location + target_type + horizon, 
      family = gaussian)
```


```{r}
# check distribution
performance::check_distribution(reg_log) |>
  plot()

# check normality of residuals
check_normality(reg_log) |>
  plot()

# heteroskedasticity of error terms - the plot takes extremly long to run
performance::check_heteroskedasticity(reg_log)
# performance::check_heteroskedasticity(reg_log) |>
#   plot()

# check influence of outliers - plot also takes very long to run
performance::check_outliers(reg_log)
# performance::check_outliers(reg_log) |>
#   plot()

```


## Model rankings

Still to do 

- restrict to full set of observations
- check how rankings change

```{r}
# find out which models have submitted forecasts for all locations and time points


```




